%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% MACHINE LEARNING BIASES %%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@manual{Gianfrancesco_2018_PotentialBiasesInMLHealth,
	title     = {Potential Biases in Machine Learning Algorithms Using Electronic Health Record Data},
	author    = {Gianfrancesco, Milena A. and Tamang, Suzanne and Yazdany, Jinoos and Schmajuk, Gabriela},
	year      = {2018},
	publisher = {JAMA Internal Medicine},
	pages     = {1544--1547}
}

@article{Plaza_2019_ConsensusAlgorithmsMedicalMisinformation,
	author  = {Plaza, Mateusz and Paladino, Lorenzo and Opara, Ijeoma and Firstenberg, Michael and Wilson, Benjamin and Papadimos, Thomas and Stawicki, Stanislaw},
	title   = {{The use of distributed consensus algorithms to curtail the spread of medical misinformation}},
	journal = {International Journal of Academic Medicine},
	volume  = {5},
	number  = {2},
	pages   = {93--99},
	doi     = {10.4103/IJAM.IJAM_47_19},
	year    = {2019},
	url     = {https://www.ijam-web.org/article.asp?issn=2455-5568;year=2019;volume=5;issue=2;spage=93;epage=99;aulast=Plaza;t=6},
	eprint  = {https://www.ijam-web.org/article.asp?issn=2455-5568;year=2019;volume=5;issue=2;spage=93;epage=99;aulast=Plaza;t=6}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% IDENTIFYING MISINFORMATION %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Wu_2019_MisinformationInSocialMedia,
	author     = {Wu, Liang and Morstatter, Fred and Carley, Kathleen M. and Liu, Huan},
	title      = {Misinformation in Social Media: Definition, Manipulation, and Detection},
	year       = {2019},
	issue_date = {December 2019},
	publisher  = {Association for Computing Machinery},
	address    = {New York, NY, USA},
	volume     = {21},
	number     = {2},
	issn       = {1931-0145},
	url        = {https://doi-org.ezproxy.rowan.edu/10.1145/3373464.3373475},
	doi        = {10.1145/3373464.3373475},
	abstract   = {The widespread dissemination of misinformation in social media has recently received a lot of attention in academia. While the problem of misinformation in social media has been intensively studied, there are seemingly different definitions for the same problem, and inconsistent results in different studies. In this survey, we aim to consolidate the observations, and investigate how an optimal method can be selected given specific conditions and contexts. To this end, we first introduce a definition for misinformation in social media and we examine the difference between misinformation detection and classic supervised learning. Second, we describe the diffusion of misinformation and introduce how spreaders propagate misinformation in social networks. Third, we explain characteristics of individual methods of misinformation detection, and provide commentary on their advantages and pitfalls. By reflecting applicability of different methods, we hope to enable the intensive research in this area to be conveniently reused in real-world applications and open up potential directions for future studies.},
	journal    = {SIGKDD Explor. Newsl.},
	month      = nov,
	pages      = {80--90},
	numpages   = {11}
}

@inproceedings{Yu_2017_convolutionalMisinformationIdentification,
	author    = {Yu, Feng and Liu, Qiang and Wu, Shu and Wang, Liang and Tan, Tieniu and others},
	title     = {A Convolutional Approach for Misinformation Identification.},
	booktitle = {IJCAI},
	pages     = {3901--3907},
	year      = {2017}
}

@article{Du_2021_DetectVaccineMisinfoWithML,
	author    = {Du, Jingcheng and Preston, Sharice and Sun, Hanxiao and Shegog, Ross and Cunningham, Rachel and Boom, Julie and Savas, Lara and Amith, Muhammad and Tao, Cui},
	title     = {Using Machine Learning-Based Approaches for the Detection and Classification of Human Papillomavirus Vaccine Misinformation: Infodemiology Study of Reddit Discussions},
	journal   = {Journal of medical Internet research},
	year      = {2021},
	month     = {Aug},
	day       = {05},
	publisher = {JMIR Publications},
	volume    = {23},
	number    = {8},
	pages     = {e26478--e26478},
	keywords  = {HPV vaccine; Reddit; deep learning; infodemiology; infoveillance; machine learning; misinformation; social media},
	abstract  = {BACKGROUND: The rapid growth of social media as an information channel has made it possible to quickly spread inaccurate or false vaccine information, thus creating obstacles for vaccine promotion. OBJECTIVE: The aim of this study is to develop and evaluate an intelligent automated protocol for identifying and classifying human papillomavirus (HPV) vaccine misinformation on social media using machine learning (ML)-based methods. METHODS: Reddit posts (from 2007 to 2017, N=28,121) that contained keywords related to HPV vaccination were compiled. A random subset (2200/28,121, 7.82{\%}) was manually labeled for misinformation and served as the gold standard corpus for evaluation. A total of 5 ML-based algorithms, including a support vector machine, logistic regression, extremely randomized trees, a convolutional neural network, and a recurrent neural network designed to identify vaccine misinformation, were evaluated for identification performance. Topic modeling was applied to identify the major categories associated with HPV vaccine misinformation. RESULTS: A convolutional neural network model achieved the highest area under the receiver operating characteristic curve of 0.7943. Of the 28,121 Reddit posts, 7207 (25.63{\%}) were classified as vaccine misinformation, with discussions about general safety issues identified as the leading type of misinformed posts (2666/7207, 36.99{\%}). CONCLUSIONS: ML-based approaches are effective in the identification and classification of HPV vaccine misinformation on Reddit and may be generalizable to other social media platforms. ML-based methods may provide the capacity and utility to meet the challenge involved in intelligent automated monitoring and classification of public health misinformation on social media platforms. The timely identification of vaccine misinformation on the internet is the first step in misinformation correction and vaccine promotion.},
	note      = {34383667[pmid]},
	note      = {PMC8380585[pmcid]},
	note      = {v23i8e26478[PII]},
	issn      = {1438-8871},
	doi       = {10.2196/26478},
	url       = {https://pubmed.ncbi.nlm.nih.gov/34383667},
	url       = {https://doi.org/10.2196/26478},
	language  = {eng}
}

@article{Kata_2021_PostmodernAntiVax,
	title    = {A postmodern Pandora's box: Anti-vaccination misinformation on the Internet},
	journal  = {Vaccine},
	volume   = {28},
	number   = {7},
	pages    = {1709--1716},
	year     = {2010},
	issn     = {0264-410X},
	doi      = {https://doi.org/10.1016/j.vaccine.2009.12.022},
	url      = {https://www.sciencedirect.com/science/article/pii/S0264410X09019264},
	author   = {Kata, Anna},
	keywords = {Anti-vaccination, Misinformation, Internet},
	abstract = {The Internet plays a large role in disseminating anti-vaccination information. This paper builds upon previous research by analyzing the arguments proffered on anti-vaccination websites, determining the extent of misinformation present, and examining discourses used to support vaccine objections. Arguments around the themes of safety and effectiveness, alternative medicine, civil liberties, conspiracy theories, and morality were found on the majority of websites analyzed; misinformation was also prevalent. The most commonly proposed method of combating this misinformation is through better education, although this has proven ineffective. Education does not consider the discourses supporting vaccine rejection, such as those involving alternative explanatory models of health, interpretations of parental responsibility, and distrust of expertise. Anti-vaccination protestors make postmodern arguments that reject biomedical and scientific “facts” in favour of their own interpretations. Pro-vaccination advocates who focus on correcting misinformation reduce the controversy to merely an “educational” problem; rather, these postmodern discourses must be acknowledged in order to begin a dialogue.}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% CROWD DETECTING MISINFORMATION %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Resnick_2021_InformedCrowdsIdentifyMisinformation,
	author     = {Resnick, Paul and Alfayez, Aljohara and Im, Jane and Gilbert, Eric},
	title      = {Informed Crowds Can Effectively Identify Misinformation},
	journal    = {CoRR},
	volume     = {abs/2108.07898},
	year       = {2021},
	url        = {https://arxiv.org/abs/2108.07898},
	eprinttype = {arXiv},
	eprint     = {2108.07898},
	timestamp  = {Mon, 23 Aug 2021 14:07:13 +0200},
	biburl     = {https://dblp.org/rec/journals/corr/abs-2108-07898.bib},
	bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Roitero_2020_CrowdIdentifyMisinformationObjectively,
	author    = {Roitero, Kevin and Soprano, Michael and Fan, Shaoyang and Spina, Damiano and Mizzaro, Stefano and Demartini, Gianluca},
	title     = {Can The Crowd Identify Misinformation Objectively? The Effects of Judgment Scale and Assessor's Background},
	year      = {2020},
	isbn      = {9781450380164},
	publisher = {Association for Computing Machinery},
	address   = {New York, NY, USA},
	url       = {https://doi.org/10.1145/3397271.3401112},
	doi       = {10.1145/3397271.3401112},
	abstract  = {Truthfulness judgments are a fundamental step in the process of fighting misinformation, as they are crucial to train and evaluate classifiers that automatically distinguish true and false statements. Usually such judgments are made by experts, like journalists for political statements or medical doctors for medical statements. In this paper, we follow a different approach and rely on (non-expert) crowd workers. This of course leads to the following research question: Can crowdsourcing be reliably used to assess the truthfulness of information and to create large-scale labeled collections for information credibility systems? To address this issue, we present the results of an extensive study based on crowdsourcing: we collect thousands of truthfulness assessments over two datasets, and we compare expert judgments with crowd judgments, expressed on scales with various granularity levels. We also measure the political bias and the cognitive background of the workers, and quantify their effect on the reliability of the data provided by the crowd.},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages     = {439--448},
	numpages  = {10},
	keywords  = {crowdsourcing, classification, information credibility},
	location  = {Virtual Event, China},
	series    = {SIGIR '20}
}

@article{Pennycook_2021_CrowdsourcedJudgements,
	author    = {Pennycook, Gordon and Rand, David G.},
	title     = {Fighting misinformation on social media using crowdsourced judgments of news source quality},
	volume    = {116},
	number    = {7},
	pages     = {2521--2526},
	year      = {2019},
	doi       = {10.1073/pnas.1806781116},
	publisher = {National Academy of Sciences},
	abstract  = {Many people consume news via social media. It is therefore desirable to reduce social media users{\textquoteright} exposure to low-quality news content. One possible intervention is for social media ranking algorithms to show relatively less content from sources that users deem to be untrustworthy. But are laypeople{\textquoteright}s judgments reliable indicators of quality, or are they corrupted by either partisan bias or lack of information? Perhaps surprisingly, we find that laypeople{\textemdash}on average{\textemdash}are quite good at distinguishing between lower- and higher-quality sources. These results indicate that incorporating the trust ratings of laypeople into social media ranking algorithms may prove an effective intervention against misinformation, fake news, and news content with heavy political bias.Reducing the spread of misinformation, especially on social media, is a major challenge. We investigate one potential approach: having social media platform algorithms preferentially display content from news sources that users rate as trustworthy. To do so, we ask whether crowdsourced trust ratings can effectively differentiate more versus less reliable sources. We ran two preregistered experiments (n = 1,010 from Mechanical Turk and n = 970 from Lucid) where individuals rated familiarity with, and trust in, 60 news sources from three categories: (i) mainstream media outlets, (ii) hyperpartisan websites, and (iii) websites that produce blatantly false content ({\textquotedblleft}fake news{\textquotedblright}). Despite substantial partisan differences, we find that laypeople across the political spectrum rated mainstream sources as far more trustworthy than either hyperpartisan or fake news sources. Although this difference was larger for Democrats than Republicans{\textemdash}mostly due to distrust of mainstream sources by Republicans{\textemdash}every mainstream source (with one exception) was rated as more trustworthy than every hyperpartisan or fake news source across both studies when equally weighting ratings of Democrats and Republicans. Furthermore, politically balanced layperson ratings were strongly correlated (r = 0.90) with ratings provided by professional fact-checkers. We also found that, particularly among liberals, individuals higher in cognitive reflection were better able to discern between low- and high-quality sources. Finally, we found that excluding ratings from participants who were not familiar with a given news source dramatically reduced the effectiveness of the crowd. Our findings indicate that having algorithms up-rank content from trusted media outlets may be a promising approach for fighting the spread of misinformation on social media.},
	issn      = {0027-8424},
	url       = {https://www.pnas.org/content/116/7/2521},
	eprint    = {https://www.pnas.org/content/116/7/2521.full.pdf},
	journal   = {Proceedings of the National Academy of Sciences}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% ATTENTION MECHANISMS %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Pennycook_2021_AttentionToAccuracy,
	author   = {Pennycook, Gordon and Epstein, Ziv and Mosleh, Mohsen and Arechar, Antonio A. and Eckles, Dean and Rand, David G.},
	title    = {Shifting attention to accuracy can reduce misinformation online},
	journal  = {Nature},
	year     = {2021},
	month    = {Apr},
	day      = {01},
	volume   = {592},
	number   = {7855},
	pages    = {590--595},
	abstract = {In recent years, there has been a great deal of concern about the proliferation of false and misleading news on social media1--4. Academics and practitioners alike have asked why people share such misinformation, and sought solutions to reduce the sharing of misinformation5--7. Here, we attempt to address both of these questions. First, we find that the veracity of headlines has little effect on sharing intentions, despite having a large effect on judgments of accuracy. This dissociation suggests that sharing does not necessarily indicate belief. Nonetheless, most participants say it is important to share only accurate news. To shed light on this apparent contradiction, we carried out four survey experiments and a field experiment on Twitter; the results show that subtly shifting attention to accuracy increases the quality of news that people subsequently share. Together with additional computational analyses, these findings indicate that people often share misinformation because their attention is focused on factors other than accuracy---and therefore they fail to implement a strongly held preference for accurate sharing. Our results challenge the popular claim that people value partisanship over accuracy8,9, and provide evidence for scalable attention-based interventions that social media platforms could easily implement to counter misinformation online.},
	issn     = {1476-4687},
	doi      = {10.1038/s41586-021-03344-2},
	url      = {https://doi.org/10.1038/s41586-021-03344-2}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% PROPOGATION OF MISINFORMATION %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

